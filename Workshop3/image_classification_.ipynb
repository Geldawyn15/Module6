{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat ou Chien !! une méthode d'apprentissage automatique.\n",
    "\n",
    "Dans une entreprise de marketing, on veut faire une étude sur les clients qui fréquentent un grand magasin. L'idée est d'estimer le pourcentage de clients qui ont des chats et ceux qui ont des chiens, afin de prendre des décisions marketing ciblées. Vous proposez d'utiliser une caméra pour détecter et compter les deux animaux dans le magasin. La première étape du projet est de développer un modèle qui peut détecter le chat ou le chien. Ainsi, dans ce brief, en utilisant une base de données, vous allez entrainer un modèle d'apprentissage automatique avec un apprentissage supervisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veille technologique: Opencv python\n",
    "\n",
    "- Préparation données imagerie pour méthode classique d'apprentissage automatique\n",
    "- Entrainement et évaluation (similaire aux briefs précédents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use opencv to load and display the image\n",
    "import os\n",
    "import cv2\n",
    "from skimage.io import imread, imsave, imshow\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Préparer data \n",
    "# size = 150\n",
    "# # repertoir d'images avec deux sous dossiers \"Cat\" et \"Dog\"\n",
    "# image_directory = 'PetImages/'\n",
    "# images = []  # liste pour images  \n",
    "# labels = []  # liste pour Label (0 ou 1) pour deux classes.\n",
    "\n",
    "# # utiliser \"os\" pour avoir les noms des images dans chaque sous dossier\n",
    "# cat_images = os.path.join(image_directory, 'Cat')\n",
    "# dog_images = os.path.join(image_directory, 'Dog')\n",
    "\n",
    "# # utiliser une boucle pour lire chaque image, redimensionner en (150,150,3),\n",
    "# # et la mettre dans images, et mettre le label(0 ou 1) selon le type dans \"label\"\n",
    "\n",
    "# # il y a des images corrumpues, utiliser try ... catch except pour les ignorer\n",
    "# size = 150\n",
    "\n",
    "# def resize_image(chemin_image):\n",
    "#     try:\n",
    "#         image = cv2.imread(chemin_image)\n",
    "#         image_redimensionnee = cv2.resize(image, (size, size))\n",
    "#         return image_redimensionnee\n",
    "#     except Exception as e:\n",
    "#         print(\"Erreur lors de la lecture de l'image :\", e)\n",
    "#         return None\n",
    "    \n",
    "    \n",
    "# # boucle pour les images Cat\n",
    "# for file in os.listdir(cat_images):\n",
    "#     image_path = os.path.join(cat_images, file)\n",
    "#     if os.path.isfile(image_path):\n",
    "#         image = resize_image(image_path)\n",
    "#         if image is not None:\n",
    "#             images.append(image)\n",
    "#             labels.append(0)  \n",
    "\n",
    "# # boucle pour les images Dog\n",
    "\n",
    "# for file in os.listdir(dog_images):\n",
    "#     image_path = os.path.join(dog_images, file)\n",
    "#     if os.path.isfile(image_path):\n",
    "#         image = resize_image(image_path)\n",
    "#         if image is not None:\n",
    "#             images.append(image)\n",
    "#             labels.append(1)  \n",
    "\n",
    "# # transformer les listes en numpy \n",
    "# images_numpy = np.asarray(images)\n",
    "# labels_numpy = np.asarray(labels)\n",
    "# # save data as \".npy\" file\n",
    "# np.save('images.npy',images_numpy)\n",
    "# np.save('labels.npy',labels_numpy)\n",
    "\n",
    "# # show shape\n",
    "# print(\"Shape des images :\", images_numpy.shape)\n",
    "# print(\"Shape des labels :\", labels_numpy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for classical machine learning model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images = np.load('images.npy')\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "# futiliser reshape pour redimensionner les données images (exemple: (120,150,150,3) ---> (120,150*150*3)\n",
    "images_reshaped = images.reshape(images.shape[0], -1)\n",
    "\n",
    "\n",
    "# split les données en train et test avec \"stratification\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_reshaped, labels, test_size=0.2, random_state=42, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialiser le classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# entrainer le classifier\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67      2496\n",
      "           1       0.67      0.61      0.64      2494\n",
      "\n",
      "    accuracy                           0.65      4990\n",
      "   macro avg       0.65      0.65      0.65      4990\n",
      "weighted avg       0.65      0.65      0.65      4990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate classifier\n",
    "from sklearn.metrics import classification_report\n",
    "# predire\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluer avec classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Rapport de classification :\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essayer de normaliser chaque image entre 0 et 255 et rentrainer le modèle. Y a-t-il une amélioration ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      2496\n",
      "           1       0.00      0.00      0.00      2494\n",
      "\n",
      "    accuracy                           0.50      4990\n",
      "   macro avg       0.25      0.50      0.33      4990\n",
      "weighted avg       0.25      0.50      0.33      4990\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images_normalized = images / 255.0\n",
    "\n",
    "# futiliser reshape pour redimensionner les données images (exemple: (120,150,150,3) ---> (120,150*150*3)\n",
    "images_reshaped = images_normalized.reshape(images_normalized.shape[0], -1)\n",
    "\n",
    "\n",
    "# split les données en train et test avec \"stratification\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_reshaped, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# evaluate classifier\n",
    "from sklearn.metrics import classification_report\n",
    "# predire\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluer avec classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Rapport de classification :\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networ MLP\n",
    "\n",
    "Entrainer un modèle MLP pour detecter la class Dog ou Cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 67500)]           0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               8640128   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8656769 (33.02 MB)\n",
      "Trainable params: 8656769 (33.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# use PCA to reduce dimensions\n",
    "# check this tuto: https://www.askpython.com/python/examples/principal-component-analysis-for-image-data\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# creer un reseau de neurone avec une couche d'entrée de taille (150*150*3), deux couches caché de taille 128 et une activation \"relu\". \n",
    "# Dernière couche de taille 1 avec une activation sigmoid. Choisir la bonne \"loss function\" et \"optimizer\"\n",
    "\n",
    "input_shape = (150*150*3,)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = Dense(128, activation='relu')(inputs)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "125/125 [==============================] - 29s 211ms/step - loss: 1.4270 - accuracy: 0.5269 - val_loss: 0.7807 - val_accuracy: 0.5654\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.7620 - accuracy: 0.5687 - val_loss: 0.7490 - val_accuracy: 0.5514\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.6707 - accuracy: 0.5995 - val_loss: 0.6979 - val_accuracy: 0.5736\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.6768 - accuracy: 0.5978 - val_loss: 0.6601 - val_accuracy: 0.6042\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 19s 153ms/step - loss: 0.6896 - accuracy: 0.5952 - val_loss: 0.6512 - val_accuracy: 0.6085\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.6596 - accuracy: 0.6124 - val_loss: 0.7542 - val_accuracy: 0.5353\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.6787 - accuracy: 0.6024 - val_loss: 0.6727 - val_accuracy: 0.6055\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.6583 - accuracy: 0.6155 - val_loss: 0.6809 - val_accuracy: 0.5877\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 22s 180ms/step - loss: 0.6512 - accuracy: 0.6193 - val_loss: 0.6626 - val_accuracy: 0.6112\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 21s 167ms/step - loss: 0.6658 - accuracy: 0.5913 - val_loss: 0.6526 - val_accuracy: 0.6150\n"
     ]
    }
   ],
   "source": [
    "# entrainer le modèle avec validation_split = 2, epochs = 20, et un batch_size = 128\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=20, batch_size=128, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 3s 13ms/step\n",
      "Rapport de classification pour le modèle MLP :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.42      0.52      2496\n",
      "           1       0.58      0.78      0.66      2494\n",
      "\n",
      "    accuracy                           0.60      4990\n",
      "   macro avg       0.62      0.60      0.59      4990\n",
      "weighted avg       0.62      0.60      0.59      4990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate MLP\n",
    "# evaluate classifier\n",
    "from sklearn.metrics import classification_report\n",
    "# predire\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluer avec classification_report\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred_classes)\n",
    "print(\"Rapport de classification pour le modèle MLP :\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67500\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e29c752e75e91034d0c40602915a17cb0379d8f99d244b8deba46517b7d2192"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('fc': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
