{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Utilisateur\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "#for machine learning - classification\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#for visualization\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# fro NLP\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "1    1005\n",
       "0     951\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('youtube/Youtube01-Psy.csv')\n",
    "df2 = pd.read_csv('youtube/Youtube02-KatyPerry.csv')\n",
    "df3 = pd.read_csv('youtube/Youtube03-LMFAO.csv')\n",
    "df4 = pd.read_csv('youtube/Youtube04-Eminem.csv')\n",
    "df5 = pd.read_csv('youtube/Youtube05-Shakira.csv')\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4, df5])\n",
    "df = df[['CONTENT', 'CLASS']].copy()\n",
    "df.CLASS.value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Hello! I'm Marian, I'm a singer from Venezuela...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Check out this video on YouTube:﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Plz subscribe to my channel and I will subscri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>I wish that guy wasn&amp;#39;t so protective geeze﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>why are they 5million comments when there is o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT  CLASS\n",
       "34   Hello! I'm Marian, I'm a singer from Venezuela...      1\n",
       "376                  Check out this video on YouTube:﻿      1\n",
       "50   Plz subscribe to my channel and I will subscri...      1\n",
       "202    I wish that guy wasn&#39;t so protective geeze﻿      0\n",
       "250  why are they 5million comments when there is o...      0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"j'ai beacoup mangé!\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = 'J\\'ai BEACOUP mangé!'\n",
    "phrase.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'would', 'like', 'an', 'orange', 'juice', ',', 'and', 'a', 'sandwich', '!']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize('I would like an orange juice, and a sandwich!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 179 stopwords\n",
      "Les 10 premiers sont ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "stopW = stopwords.words('english')\n",
    "print('Il y a {} stopwords'.format(len(stopW)))\n",
    "print('Les 10 premiers sont {}'.format(stopW[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tokens: ['I', 'would', 'like', 'an', 'orange', 'juice', ',', 'and', 'a', 'sandwich', '!']\n",
      "output tokens: ['I', 'would', 'like', 'orange', 'juice', 'sandwich']\n"
     ]
    }
   ],
   "source": [
    "exclude = set(string.punctuation)\n",
    "tokens = word_tokenize('I would like an orange juice, and a sandwich!')\n",
    "print('input tokens: {}'.format(tokens))\n",
    "stopW.extend(exclude)\n",
    "tokens_without_stopW = [word for word in tokens if word not in stopW]\n",
    "print('output tokens: {}'.format(tokens_without_stopW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'girl', 'wanted', 'to', 'play', 'with', 'their', 'parent']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "text = word_tokenize('The girls wanted to play with their parents')\n",
    "[lemma.lemmatize(word) for word in text]                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'girl', 'want', 'to', 'play', 'with', 'their', 'parent']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "text = word_tokenize('The girls wanted to play with their parents')\n",
    "[lemma.lemmatize(lemma.lemmatize(lemma.lemmatize(word, pos='a'),pos='v'),pos='n') for word in text ]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(sent):\n",
    "    tokens = word_tokenize(sent.lower())\n",
    "    tokens = [lemma.lemmatize(lemma.lemmatize(lemma.lemmatize(w, pos='v'),pos='n'),pos='a') for w in tokens]\n",
    "    return ' '.join(tokens)\n",
    "df['CONTENT'] = df.CONTENT.apply(lambda sent: lemmatize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'girls')\n",
      "('girls', 'wanted')\n",
      "('wanted', 'to')\n",
      "('to', 'play')\n",
      "('play', 'with')\n",
      "('with', 'their')\n",
      "('their', 'parents')\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams \n",
    "tokens = word_tokenize('The girls wanted to play with their parents')\n",
    "bigrams = ngrams(tokens, 2)\n",
    "for words in bigrams:\n",
    "    print(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
